"""
SE Ranking Data Visualization Script

Visualizes backlinks and AI search data from JSON files generated by
se_ranking_api_exploration.py

Creates comprehensive charts and graphs for:
1. Backlinks analysis (link types, anchor texts, geographic distribution)
2. AI Search analysis (LLM visibility, brand presence)
"""

import json
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from datetime import datetime
import numpy as np

# Set style for better-looking charts
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 10

def load_json_data(filepath):
    """Load JSON data from file"""
    try:
        with open(filepath, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: File not found: {filepath}")
        return None
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON in {filepath}")
        return None

def format_large_number(num):
    """Format large numbers with K, M, B suffixes"""
    if num >= 1_000_000_000:
        return f"{num/1_000_000_000:.1f}B"
    elif num >= 1_000_000:
        return f"{num/1_000_000:.1f}M"
    elif num >= 1_000:
        return f"{num/1_000:.1f}K"
    else:
        return str(num)

def visualize_backlinks(data):
    """Create visualizations for backlinks data"""

    if not data or 'summary_statistics' not in data:
        print("No backlinks data available to visualize")
        return

    summary = data['summary_statistics']['summary'][0]
    metadata = data['metadata']

    # Create a figure with multiple subplots
    fig = plt.figure(figsize=(20, 12))
    fig.suptitle(f'Nike Backlinks Analysis - {metadata["target"]}',
                 fontsize=20, fontweight='bold', y=0.98)

    # 1. Overall Link Profile Metrics (Top Left)
    ax1 = plt.subplot(3, 3, 1)
    metrics = {
        'Total Backlinks': summary['backlinks'],
        'Referring Domains': summary['refdomains'],
        'Unique Subnets': summary['subnets'],
        'Unique IPs': summary['ips']
    }

    bars = ax1.barh(list(metrics.keys()), list(metrics.values()),
                     color=['#2E86AB', '#A23B72', '#F18F01', '#C73E1D'])
    ax1.set_xlabel('Count')
    ax1.set_title('Overall Link Profile', fontweight='bold', fontsize=12)
    ax1.set_xscale('log')

    # Add value labels
    for i, (bar, value) in enumerate(zip(bars, metrics.values())):
        ax1.text(value, bar.get_y() + bar.get_height()/2,
                f' {format_large_number(value)}',
                va='center', fontweight='bold')

    # 2. Link Type Breakdown (Top Center)
    ax2 = plt.subplot(3, 3, 2)
    link_types = {
        'Dofollow': summary['dofollow_backlinks'],
        'Nofollow': summary['nofollow_backlinks']
    }

    colors = ['#06A77D', '#D62828']
    wedges, texts, autotexts = ax2.pie(link_types.values(),
                                         labels=link_types.keys(),
                                         autopct='%1.1f%%',
                                         colors=colors,
                                         startangle=90)
    ax2.set_title('Dofollow vs Nofollow Links', fontweight='bold', fontsize=12)

    for autotext in autotexts:
        autotext.set_color('white')
        autotext.set_fontweight('bold')

    # 3. Authority Scores (Top Right)
    ax3 = plt.subplot(3, 3, 3)
    authority_metrics = {
        'Domain\nAuthority': summary['domain_inlink_rank'],
        'Page\nAuthority': summary['inlink_rank']
    }

    bars = ax3.bar(authority_metrics.keys(), authority_metrics.values(),
                    color=['#2E86AB', '#A23B72'], edgecolor='black', linewidth=2)
    ax3.set_ylim(0, 100)
    ax3.set_ylabel('Score (0-100)')
    ax3.set_title('Authority Scores', fontweight='bold', fontsize=12)
    ax3.axhline(y=70, color='green', linestyle='--', alpha=0.3, label='Excellent (70+)')
    ax3.axhline(y=50, color='orange', linestyle='--', alpha=0.3, label='Good (50+)')

    # Add value labels
    for bar in bars:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom', fontweight='bold', fontsize=14)

    ax3.legend(loc='upper right', fontsize=8)

    # 4. Special Link Types (Middle Left)
    ax4 = plt.subplot(3, 3, 4)
    special_links = {
        'EDU': summary['edu_backlinks'],
        'GOV': summary['gov_backlinks'],
        'Homepage': summary['from_home_page_backlinks'],
        'Text': summary['text_backlinks']
    }

    bars = ax4.bar(special_links.keys(), special_links.values(),
                    color=['#06A77D', '#F18F01', '#C73E1D', '#2E86AB'])
    ax4.set_ylabel('Count')
    ax4.set_title('Special Link Types', fontweight='bold', fontsize=12)
    ax4.set_yscale('log')

    # Add value labels
    for bar in bars:
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{format_large_number(int(height))}',
                ha='center', va='bottom', fontweight='bold', rotation=0)

    # 5. Top Anchor Texts by Referring Domains (Middle Center)
    ax5 = plt.subplot(3, 3, 5)

    top_anchors_by_refdomains = summary.get('top_anchors_by_refdomains', [])[:7]
    if top_anchors_by_refdomains:
        anchor_labels = [a['anchor'] if a['anchor'] else '[Empty]'
                        for a in top_anchors_by_refdomains]
        anchor_counts = [a['refdomains'] for a in top_anchors_by_refdomains]

        # Truncate long anchor texts
        anchor_labels = [label[:20] + '...' if len(label) > 20 else label
                        for label in anchor_labels]

        bars = ax5.barh(anchor_labels, anchor_counts, color='#2E86AB')
        ax5.set_xlabel('Referring Domains')
        ax5.set_title('Top Anchor Texts (by Domains)', fontweight='bold', fontsize=12)
        ax5.invert_yaxis()

        # Add value labels
        for i, (bar, value) in enumerate(zip(bars, anchor_counts)):
            ax5.text(value, bar.get_y() + bar.get_height()/2,
                    f' {format_large_number(value)}',
                    va='center', fontweight='bold')

    # 6. Geographic Distribution (Middle Right)
    ax6 = plt.subplot(3, 3, 6)

    top_countries = summary.get('top_countries', [])[:8]
    if top_countries:
        country_names = [c['country'].upper() for c in top_countries]
        country_counts = [c['count'] for c in top_countries]

        bars = ax6.barh(country_names, country_counts,
                        color=plt.cm.viridis(np.linspace(0.3, 0.9, len(country_names))))
        ax6.set_xlabel('Referring Domains')
        ax6.set_title('Top Countries', fontweight='bold', fontsize=12)
        ax6.invert_yaxis()

        # Add value labels
        for bar, value in zip(bars, country_counts):
            ax6.text(value, bar.get_y() + bar.get_height()/2,
                    f' {format_large_number(value)}',
                    va='center', fontweight='bold')

    # 7. TLD Distribution (Bottom Left)
    ax7 = plt.subplot(3, 3, 7)

    top_tlds = summary.get('top_tlds', [])[:6]
    if top_tlds:
        tld_labels = ['.' + t['tld'] for t in top_tlds]
        tld_counts = [t['count'] for t in top_tlds]

        colors_tld = plt.cm.Set3(np.linspace(0, 1, len(tld_labels)))
        wedges, texts, autotexts = ax7.pie(tld_counts,
                                            labels=tld_labels,
                                            autopct='%1.1f%%',
                                            colors=colors_tld,
                                            startangle=90)
        ax7.set_title('Top Level Domains', fontweight='bold', fontsize=12)

        for autotext in autotexts:
            autotext.set_fontweight('bold')

    # 8. Referring Domain Quality (Bottom Center)
    ax8 = plt.subplot(3, 3, 8)

    domain_quality = {
        'Dofollow\nDomains': summary.get('dofollow_refdomains', 0),
        'Homepage\nDomains': summary.get('from_home_page_refdomains', 0),
        'EDU\nDomains': summary.get('edu_refdomains', 0),
        'GOV\nDomains': summary.get('gov_refdomains', 0)
    }

    bars = ax8.bar(domain_quality.keys(), domain_quality.values(),
                    color=['#06A77D', '#F18F01', '#C73E1D', '#2E86AB'])
    ax8.set_ylabel('Count')
    ax8.set_title('Referring Domain Quality', fontweight='bold', fontsize=12)
    ax8.set_yscale('log')

    # Add value labels
    for bar in bars:
        height = bar.get_height()
        if height > 0:
            ax8.text(bar.get_x() + bar.get_width()/2., height,
                    f'{format_large_number(int(height))}',
                    ha='center', va='bottom', fontweight='bold', rotation=0)

    # 9. Summary Statistics Box (Bottom Right)
    ax9 = plt.subplot(3, 3, 9)
    ax9.axis('off')

    summary_text = f"""
    KEY METRICS SUMMARY
    {'='*40}

    Total Backlinks: {format_large_number(summary['backlinks'])}
    Referring Domains: {format_large_number(summary['refdomains'])}

    Domain Authority: {summary['domain_inlink_rank']}/100
    Page Authority: {summary['inlink_rank']}/100

    Dofollow Links: {(summary['dofollow_backlinks']/summary['backlinks']*100):.1f}%

    EDU Domains: {format_large_number(summary.get('edu_refdomains', 0))}
    GOV Domains: {format_large_number(summary.get('gov_refdomains', 0))}

    Unique Anchors: {format_large_number(summary['anchors'])}
    Pages w/ Backlinks: {format_large_number(summary['pages_with_backlinks'])}

    Generated: {metadata['generated_at'][:10]}
    """

    ax9.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',
             verticalalignment='center', bbox=dict(boxstyle='round',
             facecolor='wheat', alpha=0.3))

    plt.tight_layout()

    # Save the figure
    output_file = 'data/backlinks_visualization.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"Saved: {output_file}")
    plt.close()

def visualize_ai_search(data):
    """Create visualizations for AI Search data"""

    if not data or 'engines' not in data:
        print("No AI Search data available to visualize")
        return

    metadata = data['metadata']
    engines_data = data['engines']

    # Check if there's any meaningful data
    has_data = False
    for engine, engine_data in engines_data.items():
        if engine_data and engine_data.get('overview'):
            has_data = True
            break

    if not has_data:
        print("AI Search data structure exists but contains no metrics yet")
        print("Creating a placeholder visualization...")

    # Create figure
    fig = plt.figure(figsize=(18, 10))
    fig.suptitle(f'Nike AI Search Visibility - {metadata["target"]}',
                 fontsize=20, fontweight='bold', y=0.98)

    # Prepare data for visualization
    engine_names = []
    link_presence = []
    avg_positions = []
    ai_traffic = []
    prompt_counts = []

    for engine, engine_data in engines_data.items():
        if engine_data and engine_data.get('overview'):
            engine_names.append(engine.upper())

            overview = engine_data['overview']
            summary = overview.get('summary', {})

            # Extract metrics (with defaults, handling None values)
            lp = summary.get('link_presence', {})
            link_presence.append(lp.get('current') or 0)

            ap = summary.get('average_position', {})
            avg_positions.append(ap.get('current') or 0)

            traffic = summary.get('ai_opportunity_traffic', {})
            ai_traffic.append(traffic.get('current') or 0)

            prompt_counts.append(len(engine_data.get('prompts', [])))

    # If no data, create placeholder
    if not engine_names:
        engine_names = ['ChatGPT', 'Gemini', 'Perplexity', 'AI-Mode']
        link_presence = [0, 0, 0, 0]
        avg_positions = [0, 0, 0, 0]
        ai_traffic = [0, 0, 0, 0]
        prompt_counts = [0, 0, 0, 0]

    # 1. Link Presence by Engine (Top Left)
    ax1 = plt.subplot(2, 3, 1)
    bars1 = ax1.bar(engine_names, link_presence, color=plt.cm.Set2(range(len(engine_names))))
    ax1.set_ylabel('Link Presence Count')
    ax1.set_title('Link Presence Across AI Engines', fontweight='bold', fontsize=12)
    ax1.tick_params(axis='x', rotation=45)

    for bar in bars1:
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom', fontweight='bold')

    # 2. Average Position by Engine (Top Center)
    ax2 = plt.subplot(2, 3, 2)
    bars2 = ax2.bar(engine_names, avg_positions, color=plt.cm.Set3(range(len(engine_names))))
    ax2.set_ylabel('Average Position')
    ax2.set_title('Average Citation Position', fontweight='bold', fontsize=12)
    ax2.tick_params(axis='x', rotation=45)
    ax2.invert_yaxis()  # Lower position number is better

    for bar in bars2:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.1f}' if height > 0 else 'N/A',
                ha='center', va='top' if height > 0 else 'bottom', fontweight='bold')

    # 3. AI Opportunity Traffic (Top Right)
    ax3 = plt.subplot(2, 3, 3)
    bars3 = ax3.bar(engine_names, ai_traffic, color=plt.cm.Pastel1(range(len(engine_names))))
    ax3.set_ylabel('Estimated Traffic')
    ax3.set_title('AI Opportunity Traffic', fontweight='bold', fontsize=12)
    ax3.tick_params(axis='x', rotation=45)

    for bar in bars3:
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{format_large_number(int(height))}' if height > 0 else '0',
                ha='center', va='bottom', fontweight='bold')

    # 4. Prompt Counts (Bottom Left)
    ax4 = plt.subplot(2, 3, 4)
    bars4 = ax4.bar(engine_names, prompt_counts, color=plt.cm.Set1(range(len(engine_names))))
    ax4.set_ylabel('Number of Prompts')
    ax4.set_title('Tracked Prompts per Engine', fontweight='bold', fontsize=12)
    ax4.tick_params(axis='x', rotation=45)

    for bar in bars4:
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height)}',
                ha='center', va='bottom', fontweight='bold')

    # 5. Comparison Chart (Bottom Center)
    ax5 = plt.subplot(2, 3, 5)

    x = np.arange(len(engine_names))
    width = 0.35

    # Normalize data for comparison (0-100 scale)
    normalized_presence = [(lp / max(link_presence) * 100) if max(link_presence) > 0 else 0
                          for lp in link_presence]
    normalized_traffic = [(t / max(ai_traffic) * 100) if max(ai_traffic) > 0 else 0
                         for t in ai_traffic]

    bars_presence = ax5.bar(x - width/2, normalized_presence, width,
                           label='Link Presence', color='#2E86AB')
    bars_traffic = ax5.bar(x + width/2, normalized_traffic, width,
                          label='AI Traffic', color='#F18F01')

    ax5.set_ylabel('Normalized Score (0-100)')
    ax5.set_title('Comparative Performance', fontweight='bold', fontsize=12)
    ax5.set_xticks(x)
    ax5.set_xticklabels(engine_names)
    ax5.tick_params(axis='x', rotation=45)
    ax5.legend()
    ax5.set_ylim(0, 110)

    # 6. Summary Box (Bottom Right)
    ax6 = plt.subplot(2, 3, 6)
    ax6.axis('off')

    total_link_presence = sum(link_presence)
    total_prompts = sum(prompt_counts)
    total_traffic = sum(ai_traffic)

    brand_info = data.get('brand_info', {})
    brands = brand_info.get('brands', [])
    brand_text = ', '.join(brands) if brands else 'Nike'

    summary_text = f"""
    AI SEARCH SUMMARY
    {'='*35}

    Brand Tracked: {brand_text}
    Target: {metadata['target']}
    Region: {metadata['source'].upper()}

    Engines Monitored: {len(engine_names)}

    Total Link Presence: {total_link_presence}
    Total Tracked Prompts: {total_prompts}
    Est. Total AI Traffic: {format_large_number(total_traffic)}

    Status: {"Active" if total_link_presence > 0 else "Monitoring"}

    Generated: {metadata['generated_at'][:10]}

    Note: AI Search tracks brand
    visibility across ChatGPT,
    Gemini, Perplexity, and other
    Large Language Models.
    """

    ax6.text(0.1, 0.5, summary_text, fontsize=10, family='monospace',
             verticalalignment='center', bbox=dict(boxstyle='round',
             facecolor='lightblue', alpha=0.3))

    plt.tight_layout()

    # Save the figure
    output_file = 'data/ai_search_visualization.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"Saved: {output_file}")
    plt.close()

def main():

    # Load and visualize backlinks data
    print("Loading backlinks data...")
    backlinks_data = load_json_data('data/se_ranking_backlinks_nike.json')

    if backlinks_data:
        print("Creating backlinks visualizations...")
        visualize_backlinks(backlinks_data)
        print()

    # Load and visualize AI Search data
    print("Loading AI Search data...")
    ai_search_data = load_json_data('data/se_ranking_ai_search_nike.json')

    if ai_search_data:
        print("Creating AI Search visualizations...")
        visualize_ai_search(ai_search_data)
        print()

if __name__ == "__main__":
    main()
